{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DTZW4uoxCVeI"
   },
   "source": [
    "# Homework 02: Linear Classification\n",
    "\n",
    "Deadline: Monday March 13, 2023 11:59 PM (without a late penalty)\n",
    "\n",
    "---\n",
    "\n",
    "This homework consists two sections, which covers the Perceptron algorithm and logistic regression classifiers that we learned. \n",
    "\n",
    "If you are running this notebook on your local computer, please make sure it has the following packages installed\n",
    "\n",
    "- Numpy\n",
    "- Sklearn\n",
    "\n",
    "---\n",
    "\n",
    "**Requirements**:\n",
    "\n",
    "Please read the following requirements carefully, to avoid any unnecessary point deduction. \n",
    "\n",
    "1. Keep all the required results in your submission, our TAs will grade the homework based on the submitted results. (The TAs not run the code unless they have some questions about the implementation.)\n",
    "2. Your submission should only be via Canvas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CizxMwf-TTtC"
   },
   "source": [
    "## 1 The Perceptron Algorithm (5 points)\n",
    "\n",
    "### 1.1 Implementation (3.5 points)\n",
    "\n",
    "Let's implement the Perceptron algorithm described in our class lecture. \n",
    "\n",
    "First, we need to download a toy dataset from the course webpage and load it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eLBWI8RrT8pN"
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import numpy as np\n",
    "url = \"https://yangfengji.net/uva-ml-undergrad/data/separable.txt\"\n",
    "filename, headers = urllib.request.urlretrieve(url, filename=\"separable.txt\")\n",
    "\n",
    "data = arr = np.loadtxt(\"separable.txt\", delimiter=\"\\t\", dtype=float)\n",
    "X = data[:,:2] # Input\n",
    "Y = data[:,-1] # Label\n",
    "\n",
    "# Attach one column to X for capturing the bias term in classification\n",
    "X = np.concatenate((X, np.ones((X.shape[0], 1))), axis=1)\n",
    "\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qj50cVGkWCNC"
   },
   "source": [
    "Please implement the Perceptron algorithm in the following code block.\n",
    "\n",
    "Make sure your implementation has the following components\n",
    "\n",
    "- The Percpetron updating rule and the condition of when to run the updating rule;\n",
    "- The convergence criterion -- stop training when the classifier can make correct prediction of all the training examples;\n",
    "- Print out the classification weight in the end. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qlsq6j-KW0k2"
   },
   "outputs": [],
   "source": [
    "def perceptron(X, Y):\n",
    "    weights = np.zeros(3)\n",
    "    # TODO: Please add your implementation here\n",
    "\n",
    "perceptron(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x4GS1OePMtez"
   },
   "source": [
    "### 1.2 The Difference between Perceptron and Logisitic Regression (1.5 points)\n",
    "\n",
    "Please list the major difference between the Perceptron model and the Logistic Regression model as we discussed in class. Please list at least three of them.\n",
    "\n",
    "**Answer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-EZm5mHnXs7b"
   },
   "source": [
    "*Please type your answer here (double click for typing)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r_j2VR5DD6lE"
   },
   "source": [
    "## 2 Logistic Regression (9 points)\n",
    "\n",
    "Logistic regression can handle both linear separable and unseparable cases. Therefore, we will use a real-world example datasets, instead of a synthetical one. \n",
    "\n",
    "We will use the [Logistic Regression]() model from Sklearn for the questions. In other words, you don't have to implement a logistic regression model by yourself, but you need to understand how to use it and how to interpret its outputs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5b8yaLJ_EpK2"
   },
   "source": [
    "### 2.0 Download the dataset\n",
    "\n",
    "Run the following code and download the [xxx]() dataset from [OpenML](). Similar to what we explained in class, we will also use the [OridinalEncoder]() to convert the non-numeric features into numeric features. \n",
    "\n",
    "Furthermore, we will run the data split function to divide the whole dataset into a training set and a validation set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hxfQSr6dFECO"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, Y = fetch_openml(\"diabetes\", version=1, return_X_y=True)\n",
    "print(\"Read {} examples with {} features\".format(X.shape[0], X.shape[1]))\n",
    "\n",
    "print(X)\n",
    "\n",
    "trnX, valX, trnY, valY = train_test_split(X, Y, test_size=0.3, random_state=111)\n",
    "print(\"The size of training set: {}\".format(trnX.shape[0]))\n",
    "print(\"The size of validation set: {}\".format(valX.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hGJ5zqnhFEiH"
   },
   "source": [
    "### 2.1 Build the Classifier (2 points)\n",
    "\n",
    "Please follow the instructions and complete the code block for building an LR classifier. \n",
    "\n",
    "- Use the [Logistic Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) model from Sklearn with its **default** parameters.\n",
    "- Training the model and report its prediction accuracy on **both** the training and the validation sets.\n",
    "- Keep the **printed** (instead of hand typing) results in your submission for grading. Make sure the printed results have enough information about which is training accuracy and which one is validation accuracy. For example, you can use \n",
    "```python\n",
    "print(\"Training accuracy: {}\".format(trn_acc))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fwsmDKwFFmyQ"
   },
   "outputs": [],
   "source": [
    "# TODO: implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zQCfRmwmFnqP"
   },
   "source": [
    "### 2.2 Feature Pre-processing (2 points)\n",
    "\n",
    "In our lecture, we talk about three different ways to represent the features before feeding into the classifier. \n",
    "\n",
    "Pick the [OneHotEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder) to further processing the features, and building the classifier again. \n",
    "\n",
    "Please follow the instructions and complete the code block for building an LR classifier with feature pre-processing\n",
    "\n",
    "- Pick one pre-processing method to further scale or encode the features\n",
    "- Training the model and report its prediction accuracy on **both** the training and the validation sets.\n",
    "- Keep the **printed** (instead of hand typing) results in your submission for grading. Make sure the printed results have enough information about which is training accuracy and which one is validation accuracy.\n",
    "\n",
    "Note that, you can find many other pre-processing functions in Sklearn via [this link](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing). Since we only discussed the three abovementioned pre-processing methods in class, you are *not* required to do anything beyond the instruction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aWDbmNt5IiXr"
   },
   "outputs": [],
   "source": [
    "# TODO: implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v3nrHVI2IjPB"
   },
   "source": [
    "### 2.3 Justification of Pre-processing (2 points)\n",
    "\n",
    "If your implementation is correct, you should see a significant boost on both training and validation accuracies. \n",
    "\n",
    "Based on what we discussed in class, please explain why this one-hot encoding is helpful for improving classification performance.\n",
    "\n",
    "**Answer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JySvBz_4Y-s-"
   },
   "source": [
    "*Please type your answer here (double click for typing)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y8Zlz48wJyOS"
   },
   "source": [
    "### 2.4 $\\ell_2$ Regularization (1.5 points)\n",
    "\n",
    "With the pre-processed data, please train the classifiers with three different regularization coefficient. In the [Logistic Regression]() model implemented in Sklearn, the associated function argument is $C$. \n",
    "\n",
    "Please use the following three code blocks and try three different $C$ values\n",
    "\n",
    "- $C=100.0$\n",
    "- $C=1.0$\n",
    "- $C=0.01$\n",
    "\n",
    "and pirnt out \n",
    "\n",
    "- the training accuracy, and \n",
    "- the validation accuracy \n",
    "\n",
    "by following the **same** format as the previous questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nnvXilP4K3W4"
   },
   "source": [
    "$C=100.0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oap5h_QeKFej"
   },
   "outputs": [],
   "source": [
    "# TODO: LR with C=100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oZboa3xPK6vI"
   },
   "source": [
    "$C=1.0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xwAjR11sK7-o"
   },
   "outputs": [],
   "source": [
    "# TODO: LR with C=0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TndTQrHKLHFw"
   },
   "source": [
    "$C=0.01$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z9smqQS8LGZY"
   },
   "outputs": [],
   "source": [
    "# TODO: C=0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UjrDQry6LRFp"
   },
   "source": [
    "### 2.5 Explan the regularization effect (1.5 points)\n",
    "\n",
    "Based on the classification accuracies above, explain the $\\ell_2$ regularization effect for the classification performance\n",
    "\n",
    "- What is the direct effect of $\\ell_2$ regularization?\n",
    "- Does it work all the time or when it may work?\n",
    "- How do we know it works for helping avoid over-fitting?\n",
    "\n",
    "Make sure your answer covers all the three questions above.\n",
    "\n",
    "**Answer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pNXQ5LZCNCJ_"
   },
   "source": [
    "*Please type your answer here (double click for typing)*"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
